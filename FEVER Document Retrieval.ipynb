{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEVER Document Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**: the purpose of this notebook is to develop a baseline approach for scoring document retrieval on the FEVER dataset with Apache Lucene.\n",
    "\n",
    "**Input**: This document requires the Lucene index, and JSON files to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Lucene Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Distinct Claims 109810\n",
      "Num Data Points 125051\n"
     ]
    }
   ],
   "source": [
    "claims, labels, article_list, claim_set, claim_to_article = utils.extract_fever_jsonl_data(\"../train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = utils.query_lucene(claims[0])\n",
    "retrieved = utils.process_lucene_output(output)\n",
    "relevant = claim_to_article[claims[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nikolaj coster waldau worked with the fox broadcasting company '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.preprocess_article_name(claims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Searching for: nikolaj coster waldau worked fox broadcasting company',\n",
       " '316945 total matching documents',\n",
       " '1. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Ved_verdens_ende.txt',\n",
       " '2. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Nukaaka_Coster-Waldau.txt',\n",
       " '3. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/A_Second_Chance_-LRB-2014_film-RRB-.txt',\n",
       " '4. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/A_Thousand_Times_Good_Night.txt',\n",
       " '5. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/New_Amsterdam_-LRB-TV_series-RRB-.txt',\n",
       " '6. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/The_Baker_-LRB-film-RRB-.txt',\n",
       " '7. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Nikolaj.txt',\n",
       " '8. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Nikolaj_Coster-Waldau.txt',\n",
       " '9. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Coster.txt',\n",
       " '10. /home/moinnadeem/Documents/UROP/wiki-pages/processed_pages/Klown_Forever.txt',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.query_lucene(claims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.calculate_precision(retrieved, relevant, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.calculate_recall(retrieved, relevant, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Statistics to Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the Precision, Recall at one of (1,2,5,10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,2, 5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_claim(claim):\n",
    "    cleaned_claim = claim.replace(\"/\", \" \")\n",
    "    choices = query_lucene(cleaned_claim)\n",
    "    retrieved = process_lucene_output(choices)\n",
    "    relevant = claim_to_article[claim]\n",
    "    mAP = {}\n",
    "    for i in k:\n",
    "        precision = calculate_precision(retrieved=retrieved, relevant=relevant, k=i)\n",
    "        recall = calculate_recall(retrieved=retrieved, relevant=relevant, k=i)\n",
    "        mAP[i] = {}\n",
    "        mAP[i]['precision'] = precision\n",
    "        mAP[i]['recall'] = recall\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this on the CSAIL cluster, and cache the results in a `result.pkl` file. We load this file into the notebook for the purpose of documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadCached = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not loadCached:\n",
    "    result = Parallel(n_jobs=8, verbose=1)(delayed(score_claim)(k) for k in list(claim_to_article.keys())[:500])\n",
    "    with open(\"result.pkl\", \"wb\") as f:\n",
    "        pickle.dump(result, f)\n",
    "else:\n",
    "    with open(\"result.pkl\", \"rb\") as f:\n",
    "        result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatemAP(mAP, k):\n",
    "    mAP_final = {}\n",
    "    \n",
    "    for i in k:\n",
    "        mAP_final[i] = {}\n",
    "        mAP_final[i]['precision'] = []\n",
    "        mAP_final[i]['recall'] = []\n",
    "        \n",
    "    for ap in mAP:\n",
    "        for k, v in ap.items():\n",
    "            mAP_final[k]['precision'].append(v['precision'])\n",
    "            mAP_final[k]['recall'].append(v['recall'])\n",
    "\n",
    "    return mAP_final\n",
    "\n",
    "def displaymAP(mAP):\n",
    "    for k, v in mAP.items():\n",
    "        for k_i, v_i in v.items():\n",
    "            print(\"{} @ {}: {}\".format(k_i, k, np.mean(v_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = calculatemAP(result, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall @ 1: 0.20031331520793064\n",
      "precision @ 1: 0.02151639967500445\n",
      "recall @ 2: 0.28886552397970694\n",
      "precision @ 2: 0.031180563702168523\n",
      "recall @ 10: 0.5110500005811957\n",
      "precision @ 10: 0.055638976872308885\n",
      "recall @ 5: 0.41472813779176937\n",
      "precision @ 5: 0.045006886603492405\n"
     ]
    }
   ],
   "source": [
    "displaymAP(mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
